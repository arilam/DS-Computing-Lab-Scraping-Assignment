{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from threading import Thread\n",
    "import math\n",
    "import pandas as pd\n",
    "import queue\n",
    "import requests\n",
    "\n",
    "# Global variables and initilization\n",
    "START_URL = 'https://www.tourradar.com/d/japan?'\n",
    "columns = [\"Tour Name\", \"Price (Euro)\"]\n",
    "result = pd.DataFrame(columns=columns)\n",
    "my_queue = queue.Queue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_urls():\n",
    "    url_list = []\n",
    "    # The first page uses a different post-fix in the URL than the others\n",
    "    url_list.append(START_URL)\n",
    "    for page in range(2, find_total_pages() + 1):\n",
    "        url_list.append(START_URL + \"page=\" + str(page))\n",
    "\n",
    "    return url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_total_pages():\n",
    "    tour_sum = 0\n",
    "    tour_per_page = 0\n",
    "    soup = BeautifulSoup(requests.get(START_URL).text, 'html.parser')\n",
    "    # Find how many tours in total\n",
    "    for div in soup.find_all(\"div\", class_ = \"stat\"):\n",
    "        tour_sum = int(div.h2.text.split()[0])\n",
    "        \n",
    "    # Find how many tours per page\n",
    "    for div in soup.find_all(\"div\", class_ = \"list\"):\n",
    "        tour_per_page = len(soup.find_all(\"div\", class_ = \"bm\"))\n",
    "    \n",
    "    # The answer is the round up value of the division\n",
    "    return math.ceil(tour_sum/tour_per_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker(url, queue):\n",
    "    \n",
    "    soup = BeautifulSoup(requests.get(url).text, 'html.parser')\n",
    "\n",
    "    titles = []\n",
    "    prices = []\n",
    "    for div_list in soup.find_all(\"div\", class_ = \"list\"):\n",
    "        # Find all tour titles\n",
    "        for div in soup.find_all(\"div\", class_ = \"bm\"):\n",
    "            titles.append(div.a.text)\n",
    "            \n",
    "        # Find all tour prices\n",
    "        for span in soup.find_all(\"span\", class_ = \"prv\"):\n",
    "            # Remove thousands separator in US and European formats\n",
    "            prices.append(int(span.text.replace(',', '').replace('.', '')))\n",
    "    \n",
    "    queue.put(list(zip(titles, prices)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create all urls for the data retrieval\n",
    "urls = make_urls()\n",
    "\n",
    "# Run threads to start the work!\n",
    "all_threads = []\n",
    "for url in urls:\n",
    "    t = Thread(target=worker, args=(url, my_queue))\n",
    "    t.start()\n",
    "    all_threads.append(t)\n",
    "    \n",
    "# Get data from queue and add to DataFrame\n",
    "result_count = 0\n",
    "while result_count < len(urls):\n",
    "    data = my_queue.get()\n",
    "    result = result.append(pd.DataFrame(data, columns=columns))\n",
    "    result_count += 1\n",
    "    \n",
    "# Write the final results to a cvs file\n",
    "result.to_csv('tour_to_japan.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
